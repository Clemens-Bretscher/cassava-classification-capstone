{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZv_7gqAAA7t"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUqT3RIsEUOh"
   },
   "source": [
    "Since we will download a dataset from kaggle, we have to hand over our kaggle handle. You can find the handle in your kaggle account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lm9TU3Nexubm"
   },
   "outputs": [],
   "source": [
    "#download kaggle api (kaggle.json) and import it here\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIa_ywoxfavs"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCZ_Vy8YfZus"
   },
   "outputs": [],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gNdPBHTI_0zQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulosgidyelew/Desktop/cassava-classification-capstone/.venv/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os, sys \n",
    "sys.path.append(os.path.dirname(os.path.realpath('/Users/paulosgidyelew/Desktop/cassava-classification-capstone/src')))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, InputLayer, Dense, Dropout, BatchNormalization, Conv2D, Activation, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD, Adagrad\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import warnings\n",
    "import mlflow\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, fbeta_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import itertools, cv2\n",
    "# user defined module\n",
    "from src import confusion_matrix\n",
    "\n",
    "# mlflow parameters:\n",
    "EXPERIMENT_NAME = \"Classava_capstone\"\n",
    "TRACKING_URI = \"https://hudsju377cddpoevnjdkfnvpwovniewnipcdsnkvn.mlflow.neuefische.de\"\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RSEED = 42\n",
    "tf.random.set_seed(RSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYqFtwiTribr"
   },
   "source": [
    "## Simple Convolutional Neural Network with balanced data... have to include that here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tiom5-qIrib3"
   },
   "source": [
    "Now we want use the first model, but use balanced data. We chose a simple convolutional model in order to get a first glance at the results. We want to use this model as a low benchmark that we want to beat in more complex models that we will use afterwards. We were using the following tutorial as a guideline for the construction of the network: <a href= \"https://www.youtube.com/watch?v=cAICT4Al5Ow&t=334s\n",
    "\">https://www.youtube.com/watch?v=cAICT4Al5Ow&t=334s</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCsdh_vzrib9"
   },
   "source": [
    "First we will set up MLflow to keep track of our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YO6-BfL3rib-"
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name='First, simple convolutional model')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AcfQa0fricA"
   },
   "source": [
    "Then we will create the architecture of the model. Here we are building three convolusional layers followed by one dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gq7dCw_aricC"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, 3, 3, input_shape=(380, 380, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,'softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sI7oihkOricE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6vv3FC7ricH"
   },
   "source": [
    "The ImageDataGenerator is used to produce the train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7UBWEXQricH"
   },
   "outputs": [],
   "source": [
    "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=90, \n",
    "                                          shear_range=0.2, \n",
    "                                          zoom_range=0.2, \n",
    "                                          horizontal_flip=True, \n",
    "                                          vertical_flip=True,\n",
    "                                          validation_split=0.2)#,\n",
    "                                          \n",
    "\n",
    "train_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                     subset='training', \n",
    "                                                     target_size=(380,380), \n",
    "                                                     class_mode='categorical', \n",
    "                                                     batch_size=32, \n",
    "                                                     shuffle=True,\n",
    "                                                     interpolation='nearest',\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     )\n",
    "val_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                   subset='validation', \n",
    "                                                   target_size=(380,380), \n",
    "                                                   class_mode='categorical', \n",
    "                                                   batch_size=32, \n",
    "                                                   shuffle=False,\n",
    "                                                   interpolation='nearest',  \n",
    "                                                   color_mode=\"rgb\"\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvSIjqkPricJ"
   },
   "source": [
    "We can look at the pictures and labels of one batch of the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9q8-n-h5ricJ"
   },
   "outputs": [],
   "source": [
    "#We can have a look at the images and labels in the batches\n",
    "#The first [i] determines the batch number and the second [i]  determines if we look at the images or its labels of this batch\n",
    "val_set[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IR3B0yMricK"
   },
   "outputs": [],
   "source": [
    "val_set[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wA6T4fabricK"
   },
   "source": [
    "We can check out one instance of our set and its corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiwH3E9XricK"
   },
   "outputs": [],
   "source": [
    "plt.imshow(val_set[1][0][30])\n",
    "print (val_set[1][1][30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2euS6GY9ricK"
   },
   "outputs": [],
   "source": [
    "#the amount of batches in the train set are:\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UF_LJUaJsL7N"
   },
   "source": [
    "We can include the class weights of the train and validation set, to balance out the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EE0Za6oUyFjs"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(train_set.classes)  \n",
    "max_val = float(max(counter.values()))    #maximum value    \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZF1fd5xvUVF"
   },
   "outputs": [],
   "source": [
    "#class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(train_set.classes), train_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMzTduzlricM"
   },
   "outputs": [],
   "source": [
    "model_checkpoint_filepath = 'checkpoints/simple_conv_model_balanced.ckpt'#h5\n",
    "model_check_point = ModelCheckpoint(model_checkpoint_filepath,\n",
    "                                    verbose=1, \n",
    "                                    save_weights_only=True, \n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True, \n",
    "                                    mode='auto')\n",
    "\n",
    "# the train_set contains both the pictures and the labels, so we do not have to define them separately\n",
    "history = model.fit(train_set, \n",
    "                    epochs=10, \n",
    "                    verbose=1, \n",
    "                    callbacks=[model_check_point], \n",
    "                    validation_data=val_set, \n",
    "                    steps_per_epoch=len(train_set),\n",
    "                    validation_steps=len(val_set), \n",
    "                    class_weight=class_weights\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDbLBZ9-ricN"
   },
   "source": [
    "Let us plot the training-process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGro28HLricN"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training','validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8_scJwOricN"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss Function')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['loss','val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vN2H5-1UricN"
   },
   "source": [
    "### Construction of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5H8EJTgfricN"
   },
   "outputs": [],
   "source": [
    "#we can use model.predict to predict the validation set and argmax gives us the the highest number for each element\n",
    "results = model.predict(val_set)\n",
    "results = np.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOyW5NY6ricN"
   },
   "outputs": [],
   "source": [
    "#report = classification_report(list_of_true_labels,results)\n",
    "report = classification_report(val_set.classes, results)\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2ophpxwricO"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_set.classes, results)\n",
    "confusion_matrix.plot_confusion_matrix(\n",
    "    cm, classes=['CBB', 'CBSD','CGM','CMD','Healthy'], \n",
    "    title='Pre-trained'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqvwwqhTricO"
   },
   "source": [
    "Calculation of the F2 score (description can be found in the simple model chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTkXuJodricO"
   },
   "outputs": [],
   "source": [
    "#Due to imbalance in our dataset we have to use 'macro' for averaging\n",
    "F2_score = fbeta_score(val_set.classes,results, average='macro', beta=2)\n",
    "print(F2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtP4K56mricO"
   },
   "source": [
    "Now let us save the parameters of the model to MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K05Vly5-ricP"
   },
   "outputs": [],
   "source": [
    "#These are the parameters that will be transfered to MlFlow for logging our experiments\n",
    "\n",
    "#Find meaningful parameters!\n",
    "params = {\n",
    "      \"number of epochs\": 10,\n",
    "      \"input_shape\": val_set[0][0][0].shape,\n",
    "      \"confusion matrix\":cm\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRWu2wwRricP"
   },
   "outputs": [],
   "source": [
    "#logging params to mlflow\n",
    "mlflow.log_params(params)\n",
    "#setting tags\n",
    "mlflow.set_tag(\"colab\", \"True\")\n",
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", history.history['accuracy'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"accuracy\", history.history['val_accuracy'][-1])\n",
    "mlflow.log_metric(\"train-\" + \"loss\", history.history['loss'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"loss\", history.history['val_loss'][-1])\n",
    "mlflow.log_metric(\"F2-score\", F2_score)\n",
    "\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "# but possible if running mlflow locally\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "or8wawKb6WJz"
   },
   "source": [
    "Using the weighted classes for the fit did not deliver good results. Oversamplling of the data would be needed. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f26546e49c7399860be80031a0c20e64d140a50285ea1c22f264eec86c8e93"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
