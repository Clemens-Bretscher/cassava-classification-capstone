{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, MaxPooling2D, Flatten,InputLayer Dense, Dropout, BatchNormalization,Conv2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras_tuner as kt\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed=seed)\n",
    "\n",
    "train_path = 'data/kaggle_data/train_images'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17118 validated image filenames belonging to 5 classes.\n",
      "Found 4279 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                            rotation_range = 45,\n",
    "                                            width_shift_range = 0.2,\n",
    "                                            height_shift_range = 0.2,\n",
    "                                            shear_range = 0.2,\n",
    "                                            zoom_range = 0.2,\n",
    "                                            horizontal_flip = True,\n",
    "                                            vertical_flip = True,\n",
    "                                            validation_split=0.2,\n",
    "                                            fill_mode = 'nearest')\n",
    "\n",
    "train_set = image_data_generator.flow_from_dataframe(data,\n",
    "                         directory = train_path,\n",
    "                         seed=seed,\n",
    "                         target_size=(380,380),\n",
    "                         subset='training',\n",
    "                         x_col = 'image_id',\n",
    "                         y_col = 'label_name',\n",
    "                         class_mode = 'categorical',\n",
    "                         shuffle = True,\n",
    "                         batch_size = 32)\n",
    "\n",
    "val_set = image_data_generator.flow_from_dataframe(data,\n",
    "                         directory = train_path,\n",
    "                         seed=seed,\n",
    "                         target_size=(380,380),\n",
    "                         subset='validation',\n",
    "                         x_col = 'image_id',\n",
    "                         y_col = 'label_name',\n",
    "                         class_mode = 'categorical',\n",
    "                         shuffle = False,\n",
    "                         batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_filepath = 'model1.h5'\n",
    "mc = ModelCheckpoint(checkpoint_filepath,\n",
    "                    verbose=1,\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_loss',\n",
    "                    mode='auto',\n",
    "                    save_best_only=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "conv_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "dense_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(InputLayer(input_shape = (380,380,3)))\n",
    "  for i in range(hp.Int('conv_layers', min_value=0, max_value=3, step=1)):\n",
    "    model.add(Conv2D(hp.Int(f'layer_{i}_filters', min_value=8,max_value=128,step=i*8),(3,3),activation='relu'))\n",
    "\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units=hp.Int('dense_layers',min_value=32,max_value=512,step=32),activation='relu'))\n",
    "\n",
    "  if hp.Boolean(\"dropout\"):\n",
    "    model.add(Dropout(rate=0.25))\n",
    "  model.add(Dense(5, 'softmax'))\n",
    "  \n",
    "  model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate',[1e-4, 1e-3, 1e-2])),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=2,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"model1_params\",\n",
    "    project_name=\"best_params\")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_set, epochs=2, verbose=1, callbacks=[mc], validation_data=val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 378, 378, 8)       224       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 376, 376, 8)       584       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 374, 374, 8)       584       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 187, 187, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 279752)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 160)               44760480  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 160)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 805       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,762,677\n",
      "Trainable params: 44,762,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(380, 380, 3))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "====================\n",
      "conv2d_3: True\n",
      "max_pooling2d_2: True\n",
      "conv2d_4: True\n",
      "max_pooling2d_3: True\n",
      "conv2d_5: True\n",
      "flatten_1: True\n",
      "dense_2: True\n",
      "dropout_1: True\n",
      "dense_3: True\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print('='*20)\n",
    "for layer in model1.layers:\n",
    "    print(f'{layer.name}: {str(layer.trainable)}')\n",
    "print('='*20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "420d7ed6979cd352c66806428606ddfc9cefeeb84853fbc86647921a84d6eb24"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
