{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZv_7gqAAA7t"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUqT3RIsEUOh"
   },
   "source": [
    "Since we will download a dataset from kaggle, we have to hand over our kaggle handle. You can find the handle in your kaggle account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lm9TU3Nexubm"
   },
   "outputs": [],
   "source": [
    "#download kaggle api (kaggle.json) and import it here\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIa_ywoxfavs"
   },
   "outputs": [],
   "source": [
    "pip install -q tensorflow tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCZ_Vy8YfZus"
   },
   "outputs": [],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gNdPBHTI_0zQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulosgidyelew/Desktop/cassava-classification-capstone/.venv/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os, sys \n",
    "sys.path.append(os.path.dirname(os.path.realpath('/Users/paulosgidyelew/Desktop/cassava-classification-capstone/src')))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, InputLayer, Dense, Dropout, BatchNormalization, Conv2D, Activation, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD, Adagrad\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import warnings\n",
    "import mlflow\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, fbeta_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import itertools, cv2\n",
    "\n",
    "from src import confusion_matrix\n",
    "\n",
    "# mlflow parameters:\n",
    "EXPERIMENT_NAME = \"Classava_capstone\"\n",
    "TRACKING_URI = \"https://hudsju377cddpoevnjdkfnvpwovniewnipcdsnkvn.mlflow.neuefische.de\"\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RSEED = 42\n",
    "tf.random.set_seed(RSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2mdHPhPZlbx"
   },
   "source": [
    "## Pre-trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hTuVVEaIJad"
   },
   "source": [
    "In order to save time on training we can use a pre-trained model. This model was already trained with images (imagenet-ilsvrc-2012-cls). It can be found here: <a href=\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\">https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb2nCueXZhxR"
   },
   "source": [
    "Let us set up MlFlow in order to track our parameters and results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lo0iQeI8ZhJE"
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name='pre-trained model')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8m-kB9YPqPz"
   },
   "source": [
    "## Feature extraction\n",
    "\n",
    "### Freeze the convolutional base\n",
    "\n",
    "It is important to freeze the convolutional base before you compile and train the model and use it as a feature extractor. Freezing (by setting `layer.trainable = False`) prevents the weights in a given layer from being updated during training. EfficientNet V2 has many layers, so setting the entire model's trainable flag to False will freeze all of them.\n",
    "\n",
    "`base_model.trainable = False`\n",
    "\n",
    "Now we will initialize the model and create its architecture. Afterwards the model gets compiled and is run. The process is stored in the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_B0kaRmsvBTO"
   },
   "outputs": [],
   "source": [
    "TFL_HUB_HANDLE = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(hub.KerasLayer(TFL_HUB_HANDLE,trainable=False))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOZyjRUqvBlO"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmM_dcs4907h"
   },
   "source": [
    "The input images should be of the size 224x224. Therefore, we have to specify these dimensions in the imagedatagenerator (target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjqCdX--9-t6"
   },
   "outputs": [],
   "source": [
    "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=90, \n",
    "                                          shear_range=0.2, \n",
    "                                          zoom_range=0.2, \n",
    "                                          horizontal_flip=True, \n",
    "                                          vertical_flip=True,\n",
    "                                          validation_split=0.2\n",
    "                                          )\n",
    "\n",
    "train_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                     subset='training', \n",
    "                                                     target_size=(224,224), \n",
    "                                                     class_mode='categorical', \n",
    "                                                     batch_size=32, \n",
    "                                                     shuffle=True,\n",
    "                                                     interpolation='nearest',\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     )\n",
    "val_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                   subset='validation', \n",
    "                                                   target_size=(224,224), \n",
    "                                                   class_mode='categorical', \n",
    "                                                   batch_size=32, \n",
    "                                                   shuffle=False,\n",
    "                                                   interpolation='nearest',  \n",
    "                                                   color_mode=\"rgb\"\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1MvkwSCvByQ"
   },
   "outputs": [],
   "source": [
    "model_checkpoint_filepath = '../callbacks/pre-trained.ckpt'\n",
    "model_check_point = ModelCheckpoint(model_checkpoint_filepath,\n",
    "                                    verbose=1, \n",
    "                                    save_weights_only=True, \n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True, \n",
    "                                    mode='auto'\n",
    "                                    )\n",
    "history = model.fit(train_set,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_check_point],\n",
    "                    validation_data=val_set, \n",
    "                    steps_per_epoch=len(train_set),\n",
    "                    validation_steps=len(val_set),\n",
    "                    batch_size=32\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2scVMzKc8g9K"
   },
   "source": [
    "Let us plot the training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNZYhxxDjtgu"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training','validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMWOirpakjdF"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss Function')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['loss','val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAEy2le-oNSj"
   },
   "source": [
    "### Construction of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muae7Cmy4GYZ"
   },
   "outputs": [],
   "source": [
    "# we can use model.predict to predict the validation set and argmax gives us the the highest number for each element\n",
    "results = model.predict(val_set)\n",
    "results = np.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKwyBeC94GYa"
   },
   "outputs": [],
   "source": [
    "# report = classification_report(list_of_true_labels,results)\n",
    "report = classification_report(val_set.classes,results)\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oC7SwPeqTgU"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_set.classes,results)\n",
    "confusion_matrix.plot_confusion_matrix(\n",
    "    cm, classes=['CBB', 'CBSD','CGM','CMD','Healthy'], \n",
    "    title='Pre-trained'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0T_y52kkoNSm"
   },
   "source": [
    "Calculation of the F2 score (description can be found in the simple model chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FI0p9ZTwoNSn"
   },
   "outputs": [],
   "source": [
    "# Due to imbalance in our dataset we have to use 'macro' for averaging\n",
    "F2_score = fbeta_score(val_set.classes,results, average='macro', beta=2)\n",
    "print(F2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5JJjQW073HO"
   },
   "outputs": [],
   "source": [
    "# These are the parameters that will be transferred to MlFlow for logging our experiments\n",
    "\n",
    "# Find meaningful parameters!\n",
    "params = {\n",
    "            \"number of epochs\": 10,\n",
    "            \"input_shape\": val_set[0][0][0].shape,\n",
    "            \"confusion matrix\":cm\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niWPzYtx73HQ"
   },
   "outputs": [],
   "source": [
    "# logging params to mlflow\n",
    "mlflow.log_params(params)\n",
    "# setting tags\n",
    "mlflow.set_tag(\"colab\", \"True\")\n",
    "# logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", history.history['accuracy'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"accuracy\", history.history['val_accuracy'][-1])\n",
    "mlflow.log_metric(\"train-\" + \"loss\", history.history['loss'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"loss\", history.history['val_loss'][-1])\n",
    "mlflow.log_metric(\"F2-score\", F2_score)\n",
    "\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "# but possible if running mlflow locally\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foTKwxJAX7pv"
   },
   "source": [
    "## Cassava-specific pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E970oaMYi1b"
   },
   "source": [
    "The pre-trained model gave us an accuracy of 0.63. The pre-trained model was trained on various images. Now we want to use a pre-trained model that was trained on cassava leaves. This model can be found here: It can be found here: <a href=\"https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1\">https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHEnCzfHYi1c"
   },
   "source": [
    "Let us set up MlFlow in order to track our parameters and results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_3ZR9TvYi1e"
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name='pre-trained model cassava-specific')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soviwUs7Yi1h"
   },
   "source": [
    "Now we will initialize the model and create its architecture. Afterwards the model gets compiled and is run. The process is stored in the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjLGW3ZzYi1h"
   },
   "outputs": [],
   "source": [
    "TFL_HUB_HANDLE = 'https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(hub.KerasLayer(TFL_HUB_HANDLE,trainable=False))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,'softmax')) # I am using 6 categories...maybe 5 is better. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6K2r4qUYi1j"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWA_ClmZYi1k"
   },
   "source": [
    "The input images should be of the size 224x224. Therefore, we have to create the input data again, using the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idbghj-wYi1l"
   },
   "outputs": [],
   "source": [
    "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=90, \n",
    "                                          shear_range=0.2, \n",
    "                                          zoom_range=0.2, \n",
    "                                          horizontal_flip=True, \n",
    "                                          vertical_flip=True,\n",
    "                                          validation_split=0.2)\n",
    "\n",
    "train_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                     subset='training', \n",
    "                                                     target_size=(224,224), \n",
    "                                                     class_mode='categorical', \n",
    "                                                     batch_size=32, \n",
    "                                                     shuffle=True,\n",
    "                                                     interpolation='nearest',\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     )\n",
    "val_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                   subset='validation', \n",
    "                                                   target_size=(224,224), \n",
    "                                                   class_mode='categorical', \n",
    "                                                   batch_size=32, \n",
    "                                                   shuffle=False,\n",
    "                                                   interpolation='nearest',  \n",
    "                                                   color_mode=\"rgb\"\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHJOtCgKYi1m"
   },
   "outputs": [],
   "source": [
    "model_checkpoint_filepath = '../callbacks/pre-trained_cassava.ckpt'\n",
    "model_check_point = ModelCheckpoint(model_checkpoint_filepath,\n",
    "                                    verbose=1, \n",
    "                                    save_weights_only=True, \n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True, \n",
    "                                    mode='auto'\n",
    "                                    )\n",
    "history = model.fit(train_set,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_check_point],\n",
    "                    validation_data=val_set, \n",
    "                    steps_per_epoch=len(train_set),\n",
    "                    validation_steps=len(val_set)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS7HtKiYopwP"
   },
   "source": [
    "We reached an accuracy of 0.84 and a loss of 0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDul_5zR8ocC"
   },
   "source": [
    "Let us plot the training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myVNYn3zYi1n"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training','validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1WeYawfYi1o"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss Function')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['loss','val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YK6-Yde1OPo7"
   },
   "source": [
    "We see that the model is underfitting, mearning that we could have gotten a higher accuracy for the trainset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4KR_g4YCZGd"
   },
   "source": [
    "### Construction of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6peMZRRay6Jo"
   },
   "outputs": [],
   "source": [
    "# we can use model.predict to predict the validation set and argmax gives us the the highest number for each element\n",
    "results = model.predict(val_set)\n",
    "results = np.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tvWulW0y6Jp"
   },
   "outputs": [],
   "source": [
    "# report = classification_report(list_of_true_labels,results)\n",
    "report = classification_report(val_set.classes,results)\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmKRFJzby6Jr"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_set.classes,results)\n",
    "confusion_matrix.plot_confusion_matrix(\n",
    "    cm, classes=['CBB', 'CBSD','CGM','CMD','Healthy'], \n",
    "    title='Pre-trained Cassava'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Mdq_G6dy6Jr"
   },
   "source": [
    "Calculation of the F2 score (description can be found in the simple model chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4YntdNfy6Jr"
   },
   "outputs": [],
   "source": [
    "# Due to imbalance in our dataset we have to use 'macro' for averaging\n",
    "F2_score = fbeta_score(val_set.classes,results, average='macro', beta=2)\n",
    "print(F2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZYJN1Aq8Aoc"
   },
   "outputs": [],
   "source": [
    "# These are the parameters that will be transferred to MlFlow for logging our experiments\n",
    "\n",
    "# Find meaningful parameters!\n",
    "params = {\n",
    "            \"number of epochs\": 10,\n",
    "            \"input_shape\": val_set[0][0][0].shape,\n",
    "            \"confusion matrix\":cm\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvL735cC8Aoc"
   },
   "outputs": [],
   "source": [
    "# logging params to mlflow\n",
    "mlflow.log_params(params)\n",
    "# setting tags\n",
    "mlflow.set_tag(\"colab\", \"True\")\n",
    "# logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", history.history['accuracy'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"accuracy\", history.history['val_accuracy'][-1])\n",
    "mlflow.log_metric(\"train-\" + \"loss\", history.history['loss'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"loss\", history.history['val_loss'][-1])\n",
    "mlflow.log_metric(\"F2-score\", F2_score)\n",
    "\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "# but possible if running mlflow locally\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU7a-Xke2lNP"
   },
   "source": [
    "## Cassava-specific pre-trained model + pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV56im8O2lNR"
   },
   "source": [
    "The cassava-specific pre-trained model gave us an accuracy of .... Now we want to test out, if a preprocessing step can improve the model. We are using a preprocessing function that is built into Keras. The preprocessing can be found in the step where the image data is produced using the imagedatagenerator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1msHUVg2lNS"
   },
   "source": [
    "Let us set up MlFlow in order to track our parameters and results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mthsyBBs2lNT"
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name='pre-trained model cassava-specific+pre-processing')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJWcrQCk2lNT"
   },
   "source": [
    "Now we will initialize the model and create its architecture. Afterwards the model gets compiled and is run. The process is stored in the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lFZypEp2lNU"
   },
   "outputs": [],
   "source": [
    "TFL_HUB_HANDLE = 'https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(hub.KerasLayer(TFL_HUB_HANDLE,trainable=False))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,'softmax')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xifTHUk2lNU"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy',metrics=[f2_micro,'accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fVmCwES2lNV"
   },
   "source": [
    "The input images should be of the size 224x224. Therefore, we have to create the input data again, using the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Md6j7JTi2lNV"
   },
   "outputs": [],
   "source": [
    "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=90, \n",
    "                                          shear_range=0.2, \n",
    "                                          zoom_range=0.2, \n",
    "                                          horizontal_flip=True, \n",
    "                                          vertical_flip=True,\n",
    "                                          validation_split=0.2,\n",
    "                                          preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "train_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                     subset='training', \n",
    "                                                     target_size=(224,224), \n",
    "                                                     class_mode='categorical', \n",
    "                                                     batch_size=32, \n",
    "                                                     shuffle=True,\n",
    "                                                     interpolation='nearest',\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     )\n",
    "val_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                   subset='validation', \n",
    "                                                   target_size=(224,224), \n",
    "                                                   class_mode='categorical', \n",
    "                                                   batch_size=32, \n",
    "                                                   shuffle=False,\n",
    "                                                   interpolation='nearest',  \n",
    "                                                   color_mode=\"rgb\"\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaAf0hcx2lNW"
   },
   "outputs": [],
   "source": [
    "model_checkpoint_filepath = '../callbacks/pre-trained_cassava_preprocessing.ckpt'\n",
    "model_check_point = ModelCheckpoint(model_checkpoint_filepath,\n",
    "                                    verbose=1, \n",
    "                                    save_weights_only=True, \n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True, \n",
    "                                    mode='auto'\n",
    "                                    )\n",
    "history = model.fit(train_set,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_check_point],\n",
    "                    validation_data=val_set, \n",
    "                    steps_per_epoch=len(train_set),\n",
    "                    validation_steps=len(val_set)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAQnPGtI2lNX"
   },
   "source": [
    "Let us plot the training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBOyyAp99vZ4"
   },
   "outputs": [],
   "source": [
    "print (history.history['accuracy'][-1],history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zo9Ohfmn2lNX"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training','validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkUw7q6M2lNY"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss Function')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['loss','val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ik4pDh8r2lNY"
   },
   "source": [
    "### Construction of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khdOU3_w2lNY"
   },
   "outputs": [],
   "source": [
    "# we can use model.predict to predict the validation set and argmax gives us the the highest number for each element\n",
    "results = model.predict(val_set)\n",
    "results = np.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuJO51Tv2lNZ"
   },
   "outputs": [],
   "source": [
    "# report = classification_report(list_of_true_labels,results)\n",
    "report = classification_report(val_set.classes,results)\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGoHsPaf2lNa"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_set.classes,results)\n",
    "confusion_matrix.plot_confusion_matrix(\n",
    "    cm, classes=['CBB', 'CBSD','CGM','CMD','Healthy'], \n",
    "    title='Pre-trained Cassava'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMMFD7iF2lNb"
   },
   "source": [
    "Calculation of the F2 score (description can be found in the simple model chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vqcLJKJ2lNb"
   },
   "outputs": [],
   "source": [
    "# Due to imbalance in our dataset we have to use 'macro' for averaging\n",
    "F2_score = fbeta_score(val_set.classes,results, average='macro', beta=2)\n",
    "print(F2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuNYW3Wa2lNb"
   },
   "outputs": [],
   "source": [
    "# These are the parameters that will be transferred to MlFlow for logging our experiments\n",
    "\n",
    "# Find meaningful parameters!\n",
    "params = {\n",
    "            \"number of epochs\": 10,\n",
    "            \"input_shape\": val_set[0][0][0].shape,\n",
    "            \"confusion matrix\":cm\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcUQxZKs2lNc"
   },
   "outputs": [],
   "source": [
    "# logging params to mlflow\n",
    "mlflow.log_params(params)\n",
    "# setting tags\n",
    "mlflow.set_tag(\"colab\", \"True\")\n",
    "# logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", history.history['accuracy'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"accuracy\", history.history['val_accuracy'][-1])\n",
    "mlflow.log_metric(\"train-\" + \"loss\", history.history['loss'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"loss\", history.history['val_loss'][-1])\n",
    "mlflow.log_metric(\"F2-score\", F2_score)\n",
    "\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "# but possible if running mlflow locally\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNFUdpQ985ay"
   },
   "source": [
    "The preprocessing step made the prediction worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEAr0lKx-pee"
   },
   "source": [
    "## Cassava-specific pre-trained model + less dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QGq6qrg-pef"
   },
   "source": [
    "Since we saw in previous models a tendency for underfitting, we will leave out some ot the dropout layers. It is likely that the model was too regularized, which made the training performance worse than the validation performance.\n",
    "Introducing more dropouts to the model will decrease the complexity of the neural network. this reduction in dimensionality of the network will induce less trainable parameters to be learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLSiBpXS-pef"
   },
   "source": [
    "Let us set up MlFlow in order to track our parameters and results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc_3jtAR-pef"
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name='pre-trained model cassava-specific')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNFTymSh-peg"
   },
   "source": [
    "Now we will initialize the model and create its architecture. Afterwards the model gets compiled and is run. The process is stored in the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olF3CzFv-peg"
   },
   "outputs": [],
   "source": [
    "TFL_HUB_HANDLE = 'https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(hub.KerasLayer(TFL_HUB_HANDLE,trainable=False))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,'softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PfUflL4-peg"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv3e0Q3B-peh"
   },
   "source": [
    "The input images should be of the size 224x224. Therefore, we have to create the input data again, using the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfmkfhTg-peh"
   },
   "outputs": [],
   "source": [
    "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=90, \n",
    "                                          shear_range=0.2, \n",
    "                                          zoom_range=0.2, \n",
    "                                          horizontal_flip=True, \n",
    "                                          vertical_flip=True,\n",
    "                                          validation_split=0.2\n",
    "                                          )\n",
    "\n",
    "train_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                     subset='training', \n",
    "                                                     target_size=(224,224), \n",
    "                                                     class_mode='categorical', \n",
    "                                                     batch_size=32, \n",
    "                                                     shuffle=True,\n",
    "                                                     interpolation='nearest',\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     )\n",
    "val_set = image_data_generator.flow_from_directory('/content/train', \n",
    "                                                   subset='validation', \n",
    "                                                   target_size=(224,224), \n",
    "                                                   class_mode='categorical', \n",
    "                                                   batch_size=32, \n",
    "                                                   shuffle=False,\n",
    "                                                   interpolation='nearest',  \n",
    "                                                   color_mode=\"rgb\"\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFRegXep-pei"
   },
   "outputs": [],
   "source": [
    "model_checkpoint_filepath = '../callbacks/pre-trained_cassava-less-dropout.ckpt'\n",
    "model_check_point = ModelCheckpoint(model_checkpoint_filepath,\n",
    "                                    verbose=1, \n",
    "                                    save_weights_only=True, \n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True, \n",
    "                                    mode='auto'\n",
    "                                    )\n",
    "history = model.fit(train_set,\n",
    "                    epochs=1,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_check_point],\n",
    "                    validation_data=val_set, \n",
    "                    steps_per_epoch=len(train_set),\n",
    "                    validation_steps=len(val_set)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7H12sEng-pei"
   },
   "source": [
    "We reached an accuracy of 0.88 and a loss of 0.39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDTAUA6R-pei"
   },
   "source": [
    "Let us plot the training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "is5rLT1j-pei"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['training','validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wudNx3VV-pei"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss Function')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['loss','val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOcd5Lah-pei"
   },
   "source": [
    "### Construction of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CAEBpxQ-pei"
   },
   "outputs": [],
   "source": [
    "# we can use model.predict to predict the validation set and argmax gives us the the highest number for each element\n",
    "results = model.predict(val_set)\n",
    "results = np.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGLtMsVK-pej"
   },
   "outputs": [],
   "source": [
    "# report = classification_report(list_of_true_labels,results)\n",
    "report = classification_report(val_set.classes,results)\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sW2IV88t-pej"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_set.classes,results)\n",
    "confusion_matrix.plot_confusion_matrix(\n",
    "    cm, classes=['CBB', 'CBSD','CGM','CMD','Healthy'], \n",
    "    title='Pre-trained Cassava'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-r9zQB8r-pej"
   },
   "source": [
    "Calculation of the F2 score (description can be found in the simple model chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tARariXH-pej"
   },
   "outputs": [],
   "source": [
    "# Due to imbalance in our dataset we have to use 'macro' for averaging\n",
    "F2_score = fbeta_score(val_set.classes,results, average='macro', beta=2)\n",
    "print(F2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VS2ClEk2-pej"
   },
   "outputs": [],
   "source": [
    "# These are the parameters that will be transferred to MlFlow for logging our experiments\n",
    "\n",
    "# Find meaningful parameters!\n",
    "params = {\n",
    "            \"number of epochs\": 10,\n",
    "            \"input_shape\": val_set[0][0][0].shape,\n",
    "            \"confusion matrix\":cm\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmlEQTLt-pej"
   },
   "outputs": [],
   "source": [
    "# logging params to mlflow\n",
    "mlflow.log_params(params)\n",
    "# setting tags\n",
    "mlflow.set_tag(\"colab\", \"True\")\n",
    "# logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", history.history['accuracy'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"accuracy\", history.history['val_accuracy'][-1])\n",
    "mlflow.log_metric(\"train-\" + \"loss\", history.history['loss'][-1])\n",
    "mlflow.log_metric(\"val-\" + \"loss\", history.history['val_loss'][-1])\n",
    "mlflow.log_metric(\"F2-score\", F2_score)\n",
    "\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "# but possible if running mlflow locally\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teMCL4nPHq4T"
   },
   "source": [
    "We want to save the model to use it later again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JcsweRrHuIX"
   },
   "outputs": [],
   "source": [
    "model.save('../saved_model/my_model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f26546e49c7399860be80031a0c20e64d140a50285ea1c22f264eec86c8e93"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
